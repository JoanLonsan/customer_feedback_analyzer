{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c829abf-156f-4702-b1c2-1de3ed25458c",
   "metadata": {},
   "source": [
    "# Building a Customer Feedback Analyzer\n",
    "\n",
    "### Dataset\n",
    "For this project, I will focus on a single dataset containing feedback from a hospitality business.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Net Promoter Score (NPS):**  \n",
    "  Measures customer loyalty by answering the question:  \n",
    "  *\"How likely is it that you would recommend this product to a friend or colleague?\"*  \n",
    "  Scores range from 0 to 10:\n",
    "  - 9–10: Promoters  \n",
    "  - 7–8: Passives  \n",
    "  - 0–6: Detractors  \n",
    "\n",
    "  **Formula:**  \n",
    "`NPS = % of Promoters - % of Detractors`\n",
    "\n",
    "- **Sentiment Analysis:**  \n",
    "  Identifies the emotional tone of reviews using pre-trained AI models:\n",
    "  - Positive  \n",
    "  - Negative  \n",
    "  - Neutral  \n",
    "\n",
    "- **Topic Modeling:**  \n",
    "  Uses embeddings to identify recurring themes in textual data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01209a-857e-4e58-bf9e-c9c63f906e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396a998-2b90-41d8-851d-a54846a36d06",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b39cfe-b5a5-41c4-b61b-2f04973fc2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "file_path = 'guest_data_with_reviews.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46147297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3549e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the number of missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with any missing values\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "# Remove rows with any missing values\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "\n",
    "# Display the shape of the cleaned DataFrame\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119500d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Plot the distribution of the 'Recomendation' column\n",
    "fig = px.histogram(df_cleaned, x='How likely are you to recommend us to a friend or colleague?', nbins = 10, title='Distribution of Recommendations Scores')\n",
    "fig.update_layout(xaxis_title='Recommendation Score', yaxis_title='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3725002-c203-493c-8123-bb280e9cd9af",
   "metadata": {},
   "source": [
    "## 2. Calculate NPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a2d87-d227-4a01-b869-3dd04b5ef978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster recommendation scores to calculate NPS\n",
    "def calculate_nps(score):\n",
    "    if score >= 9:\n",
    "        return 'Promoter'\n",
    "    elif score >= 7:\n",
    "        return 'Passive'\n",
    "    else:\n",
    "        return 'Detractor'\n",
    "\n",
    "# Apply the NPS calculation function to the DataFrame\n",
    "df_cleaned['NPS Category'] = df_cleaned['How likely are you to recommend us to a friend or colleague?'].apply(calculate_nps)\n",
    "\n",
    "# Display to confirm new column \"NPS Category\" is added\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportions of each NPS category\n",
    "nps_proportions = df_cleaned['NPS Category'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the proportions of each NPS category\n",
    "nps_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aec568",
   "metadata": {},
   "source": [
    "If the **NPS Score** is greater than zero, we can interpret it as a positive NPS: there are more promoters than detractors, indicating good customer loyalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NPS score\n",
    "nps_score = nps_proportions['Promoter'] - nps_proportions['Detractor']\n",
    "nps_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1483deb",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ce9bf",
   "metadata": {},
   "source": [
    "It may be necessary to run:\n",
    "```\n",
    "!pip install tf_keras\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cadff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Analyze the sentiment of the reviews\n",
    "df_cleaned['Sentiment'] = df_cleaned['Review'].apply(lambda review: sentiment_pipeline(review)[0]['label'])\n",
    "\n",
    "# Display the first few rows of the DataFrame with sentiment analysis results\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab3bd7",
   "metadata": {},
   "source": [
    "Sentiment analysis aligns with NPS results, showing significantly more negative resolutions than positive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sentiment distribution\n",
    "fig = px.histogram(df_cleaned, x='Sentiment', title='Sentiment Distribution', labels={'Sentiment': 'Sentiment Category'}, color='Sentiment')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c550495",
   "metadata": {},
   "source": [
    "## 4. Topic Modeling\n",
    "\n",
    "Using embeddings to extract key topics from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddde428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# 1st Step\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 2nd Step\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Visualization\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee5f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=20)\n",
    "\n",
    "# Fit and transform the reviews text\n",
    "X = vectorizer.fit_transform(df_cleaned['Review'])\n",
    "\n",
    "# Get the feature names (keywords)\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Sum up the counts of each keyword\n",
    "keyword_counts = X.toarray().sum(axis=0)\n",
    "\n",
    "# Create a DataFrame for keywords and their counts\n",
    "keywords_df = pd.DataFrame({'Keyword': keywords, 'Count': keyword_counts})\n",
    "\n",
    "# Sort the DataFrame by count in descending order\n",
    "keywords_df = keywords_df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Display the top keywords\n",
    "keywords_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "# Fit and transform the reviews text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_cleaned['Review'])\n",
    "\n",
    "# Initialize the LDA model\n",
    "lda_model = LDA(n_components=5, random_state=42)\n",
    "\n",
    "# Fit the LDA model to the TF-IDF matrix\n",
    "lda_model.fit(tfidf_matrix)\n",
    "\n",
    "# Get the feature names (keywords)\n",
    "keywords = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the top words for each topic\n",
    "n_top_words = 10\n",
    "topics = {}\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "\ttop_keywords = [keywords[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "\ttopics[f'Topic {topic_idx + 1}'] = top_keywords\n",
    "\n",
    "# Convert the topics to a DataFrame\n",
    "topics_df = pd.DataFrame(topics)\n",
    "\n",
    "# Display the topics DataFrame\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bff7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word cloud for each topic\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 10), sharex=True, sharey=True)\n",
    "\n",
    "for i, (topic, top_keywords) in enumerate(topics.items()):\n",
    "\twordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(top_keywords))\n",
    "\taxes[i].imshow(wordcloud, interpolation='bilinear')\n",
    "\taxes[i].set_title(topic, fontsize=16)\n",
    "\taxes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
